{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOsVQe7wa68o1YvvdsdBQ8a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torch.nn.functional as F\n","from torchvision import transforms\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from matplotlib.backends.backend_pdf import PdfPages"],"metadata":{"id":"n_QLGJopOgRI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_xd56C0Klyw"},"outputs":[],"source":["# Part 1: YOLO\n","\n","def run_yolo(video_path, YOLO_model):\n","  cap = cv2.VideoCapture(video_path)\n","  writer = create_video_writer(cap)\n","\n","  fps = int(cap.get(cv2.CAP_PROP_FPS))\n","  frame_interval = 3 * fps\n","\n","  frame_count = 0\n","  sheet_music_lines = []\n","  bar_lines = []\n","\n","  while True:\n","\n","      success, img = cap.read()\n","\n","      if not success:\n","          break\n","\n","      if frame_count % frame_interval == 0:\n","        cropped_images, cropped_bars = predict_and_detect(YOLO_model, img, classes=[], conf=0.5)\n","\n","        if len(cropped_images) > 1:  # There should only be 1 line of music per frame\n","              max_width = 0\n","              max_width_image = None\n","\n","              for cropped_img in cropped_images:\n","                  height, width = cropped_img.shape[:2]\n","                  if width > max_width:\n","                      max_width = width\n","                      max_width_image = cropped_img\n","\n","              cropped_images = [max_width_image]\n","\n","        if len(cropped_images) != 0:\n","          sheet_music_lines.append(cropped_images[0])\n","          bars = []\n","          for bar in cropped_bars:\n","              bars.append(bar[1])\n","\n","          bar_lines.append(bars)\n","\n","      frame_count += 1\n","\n","  writer.release()\n","\n","  assert len(bar_lines) == len(sheet_music_lines)\n","\n","  return sheet_music_lines\n","\n","def remove_highlights(img):\n","    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","    L, A, B = cv2.split(lab_img)\n","\n","    threshold = 5 # Smaller threshold <-> less lenient\n","    mask = cv2.inRange(A, 128-threshold, 128+threshold) & cv2.inRange(B, 128 - threshold, 128 + threshold)\n","\n","    # Invert mask to get non-gray areas\n","    mask_inv = cv2.bitwise_not(mask)\n","    gray_image_colored = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2BGR)\n","    result = cv2.bitwise_and(img, img, mask=mask) + cv2.bitwise_and(gray_image_colored, gray_image_colored, mask=mask_inv)\n","\n","    return result\n","\n","def predict(chosen_model, img, classes=[], conf=0.5):\n","    if classes:\n","        results = chosen_model.predict(img, classes=classes, conf=conf)\n","    else:\n","        results = chosen_model.predict(img, conf=conf)\n","\n","    return results\n","\n","\n","def predict_and_detect(chosen_model, img, classes=[], conf=0.5):\n","    results = predict(chosen_model, img, classes, conf=conf)\n","    cropped_images = []\n","    cropped_bars = []\n","\n","    for result in results:\n","        for box in result.boxes:\n","            if int(box.cls[0]) == 0: # Class 2: line\n","              x1,x2,y1,y2 = int(box.xyxy[0][0]),int(box.xyxy[0][2]),int(box.xyxy[0][1]),int(box.xyxy[0][3])\n","              cropped_img = img[y1:y2, x1:x2]\n","              colors_removed_img = remove_highlights(cropped_img)\n","              cropped_images.append(colors_removed_img)\n","\n","            if int(box.cls[0]) == 1: # Class 1: bar\n","              x1, x2 = int(box.xyxy[0][0]), int(box.xyxy[0][2])\n","              cropped_bars.append((x1, x2))\n","\n","    # return img, results, cropped_images, cropped_bars\n","    return cropped_images, cropped_bars\n","\n","# defining function for creating a writer (for mp4 videos)\n","\n","def create_video_writer(video_cap, output_filename):\n","    # grab the width, height, and fps of the frames in the video stream.\n","    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n","\n","    # initialize the FourCC and a video writer object\n","    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n","                             (frame_width, frame_height))\n","\n","    return writer"]},{"cell_type":"code","source":["# Part 2: Siamese\n","\n","def run_siamese(sheet_music_lines, siamese_model):\n","\n","  sheet_music_pairs = [\n","    (Image.fromarray(sheet_music_lines[i]), Image.fromarray(sheet_music_lines[i+1]))\n","    for i in range(len(sheet_music_lines) - 1)]\n","\n","  transform = transforms.Compose([transforms.Resize((224, 224)),\n","                                  transforms.ToTensor(),\n","                                  transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                                      std=[0.229, 0.224, 0.225])  # Same as ImageNet\n","                                  ])\n","\n","  unique_lines = []\n","  unique_lines.append(sheet_music_pairs[0][0])\n","\n","  for (img1, img2) in sheet_music_pairs:\n","    img_tensor_1 = transform(img1)\n","    img_tensor_2 = transform(img2)\n","\n","    output1, output2 = siamese_model(img_tensor_1.unsqueeze(0), img_tensor_2.unsqueeze(0))\n","\n","    distance = F.pairwise_distance(output1, output2).item()\n","\n","    if distance >= 0.7:\n","      unique_lines.append(img2)\n","\n","  return unique_lines\n"],"metadata":{"id":"7RlpNChsLyUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Part 3: ORB Sliding Window\n","\n","def run_orb_sliding_window(sheet_music_lines):\n","\n","  for image in sheet_music_lines:\n","    keypoints, descriptors = detect_and_compute(image)\n","\n","  unique_music = []\n","  unique_music.append(sheet_music_lines[0])\n","\n","  sheet_music_pairs = [\n","      (sheet_music_lines[i], sheet_music_lines[i+1])\n","      for i in range(len(sheet_music_lines) - 1)]\n","\n","  bars_idx = 1\n","\n","  for (img1, img2) in sheet_music_pairs:\n","    keypoints1, descriptors1 = detect_and_compute(np.array(img1))\n","    keypoints2, descriptors2 = detect_and_compute(np.array(img2))\n","    matches = match_descriptors(descriptors1, descriptors2, keypoints1, keypoints2, img1.shape, img2.shape)\n","    good_matches = matches[:int(len(matches) * 0.25)]\n","\n","    homography_matrix = find_homography_and_check_overlap(img1, img2, keypoints1, keypoints2, good_matches) # Assign result to homography_matrix\n","    if homography_matrix is not None: # Check if homography_matrix is not None\n","      transformed_corners = get_transformed_corners(img1.shape, homography_matrix) # Use homography_matrix\n","      bbox = compute_bounding_box(transformed_corners)\n","      image_with_bbox = draw_bounding_box(img2, bbox)\n","\n","      # Add cropped non-overlapping part of second image to array\n","      (x1, y1), (x2, y2) = bbox\n","\n","      if abs(x2 - x1) < 0.8 * img2.shape[1]:\n","        unique_music.append(img2[y1:y2, x2:img2.shape[1]])\n","\n","  stitch_and_save_images_to_pdf(unique_music=unique_music, pdf_file_path='output.pdf', align_left=True)\n","\n","def detect_and_compute(image):\n","  orb = cv2.ORB_create(\n","      nfeatures=10000,\n","      scaleFactor=1.05,\n","      nlevels=6,\n","      edgeThreshold=0,\n","      firstLevel=0,\n","      WTA_K=4,\n","      scoreType=cv2.ORB_FAST_SCORE,\n","      patchSize=31,\n","      fastThreshold=10\n","  )\n","  keypoints, descriptors = orb.detectAndCompute(image, None)\n","  return keypoints, descriptors\n","\n","def draw_keypoints(image, keypoints):\n","  image_with_keypoints = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","  cv2_imshow(image_with_keypoints)\n","  img2 = cv2.drawKeypoints(image, keypoints, None, color=(0,255,0), flags=0)\n","  cv2_imshow(img2)\n","\n","def match_descriptors(descriptors1, descriptors2, keypoints1, keypoints2, img1_shape, img2_shape):\n","  matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n","  initial_matches = matcher.match(descriptors1, descriptors2)\n","\n","  biased_matches = []\n","\n","  for initial_match in initial_matches:\n","    kp1 = keypoints1[initial_match.queryIdx].pt\n","    kp2 = keypoints2[initial_match.trainIdx].pt\n","\n","    # keypoint indices: x: 0, y:1\n","    # img_shape indices: x: 1, y: 0\n","    kp1x, kp2x = kp1[0], kp2[0]\n","    kp2x = kp2\n","\n","    x1_displacement = (img1_shape[1] - kp1[0]) / img1_shape[1]  # distance of keypoint 1 from the right end of image 1\n","    x2_displacement = kp2[0] / img2_shape[1]                    # distance of keypoint 2 from the left end of image 2\n","\n","    # This is baseline distance between descriptors\n","    # For orb, maximum distance is 256 --> use for normalization\n","    descriptor_distance = initial_match.distance / 256\n","\n","    initial_match.distance = x1_displacement + x2_displacement + 7 * descriptor_distance\n","    biased_matches.append(initial_match)\n","\n","  biased_matches = sorted(biased_matches, key=lambda x: x.distance)\n","  return biased_matches\n","\n","def draw_matches(image1, image2, keypoints1, keypoints2, matches):\n","  image_with_matches = cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches, None)\n","  cv2_imshow(image_with_matches)\n","  cv2.waitKey(0)\n","  cv2.destroyAllWindows()\n","\n","def find_homography_and_check_overlap(image1, image2, keypoints1, keypoints2, matches):\n","    if len(matches) < 4:\n","        print(\"Not enough matches to compute homography.\")\n","        return None # Return None instead of False\n","\n","    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n","    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n","\n","    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)\n","\n","    if H is not None:\n","        return H # Return the homography matrix\n","    else:\n","        return None # Return None instead of False\n","\n","def get_transformed_corners(image_shape, H):\n","    h, w, = image_shape[:2]\n","    corners = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n","    transformed_corners = cv2.perspectiveTransform(corners, H)\n","    return transformed_corners\n","\n","def compute_bounding_box(corners):\n","    x_coords, y_coords = zip(*[pt[0] for pt in corners])\n","    x_max = int(max(x_coords))\n","    x_min = 0\n","    y_min = 0\n","    y_max = int(max(y_coords))\n","    return (x_min, y_min), (x_max, y_max)\n","\n","def draw_bounding_box(image, bbox):\n","    (x_min, y_min), (x_max, y_max) = bbox\n","    output_image = image.copy()\n","    cv2.rectangle(output_image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n","    return output_image\n","\n","def draw_axis_lines(image, x1, x2):\n","    output_image = image.copy()\n","    cv2.line(output_image, (x1, 10), (x2, 10), (0, 0, 255), 2)\n","    return output_image\n","\n","def display_image_at_actual_size(image, save_path=None):\n","    \"\"\"\n","    Display an image in its original size using plt.imshow(). Optionally save it as a PDF page.\n","    \"\"\"\n","    h, w = image.shape[:2]\n","    dpi = plt.rcParams['figure.dpi']  # Use current DPI setting of matplotlib\n","    figsize = w / dpi, h / dpi  # Calculate the figure size in inches\n","    fig, ax = plt.subplots(figsize=figsize)\n","    ax.imshow(image)\n","    ax.axis('off')  # Turn off axis\n","    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Remove padding around the image\n","\n","    if save_path:\n","        fig.savefig(save_path, format='pdf')\n","    plt.close(fig)\n","\n","def pad_image_to_height(image, target_height):\n","    \"\"\"\n","    Pads the image vertically to match the target height.\n","    \"\"\"\n","    h, w = image.shape[:2]\n","    if h == target_height:\n","        return image\n","\n","    # Calculate padding\n","    pad_height = target_height - h\n","    pad_top = pad_height // 2\n","    pad_bottom = pad_height - pad_top\n","\n","    # Pad the image using np.pad\n","    padded_image = np.pad(image, ((pad_top, pad_bottom), (0, 0), (0, 0)), mode='constant', constant_values=255)\n","    return padded_image\n","\n","def pad_image_to_width(image, target_width, align_left=True):\n","    \"\"\"\n","    Pads the image horizontally to match the target width.\n","    If `align_left` is True, pads only on the right side to align the image to the left.\n","    \"\"\"\n","    h, w = image.shape[:2]\n","    pad_width = target_width - w\n","\n","    if pad_width <= 0:\n","        return image  # No padding needed\n","\n","    if align_left:\n","        # Padding only on the right side\n","        pad_left = 0\n","        pad_right = pad_width\n","    else:\n","        # Padding equally on both sides\n","        pad_left = pad_width // 2\n","        pad_right = pad_width - pad_left\n","\n","    padded_image = np.pad(image, ((0, 0), (pad_left, pad_right), (0, 0)), mode='constant', constant_values=255)\n","    return padded_image\n","\n","def crop_image_top_bottom(image, pixels=5):\n","    \"\"\"Crop a specified number of pixels from the top and bottom of the image.\"\"\"\n","    h, w = image.shape[:2]\n","    return image[pixels:h-pixels, :]  # Slice the image to remove `pixels` from top and bottom\n","\n","def crop_image_width(image, crop_width):\n","    \"\"\"Crop an image to a specified width.\"\"\"\n","    return image[:, :crop_width]  # Keep only the first `crop_width` columns\n","\n","def add_margin(image, margin):\n","    \"\"\"\n","    Add a white margin around the image.\n","    \"\"\"\n","    h, w = image.shape[:2]\n","    return np.pad(image, ((margin, margin), (margin, margin), (0, 0)), mode='constant', constant_values=255)\n","\n","def stitch_and_save_images_to_pdf(unique_music, pdf_file_path, width_threshold=int(plt.rcParams['figure.dpi'] * 8.5), height_threshold=int(plt.rcParams['figure.dpi'] * 11), align_left=True, margin=10):\n","    \"\"\"\n","    Stitch images together, and save each stitched result as a page in a PDF.\n","    \"\"\"\n","    stitched_row = []\n","    stitched_rows = []  # Store all rows to stack vertically\n","    current_width = 0  # Track the current width of the stitched images\n","    current_height = 0  # Track the current height of the stitched rows\n","    max_row_height = 0  # Track the height of the tallest image in the row\n","    max_row_width = 0  # Track the width of the widest row\n","\n","    pdf_pages = PdfPages(pdf_file_path)\n","\n","    for line in unique_music:\n","        line_np = np.array(line)  # Convert to NumPy array if needed\n","        h, w = line_np.shape[:2]  # Get the height and width of the current image\n","\n","        # If adding the next image will exceed the width threshold, handle the current row\n","        if current_width + w > width_threshold:\n","            remaining_width = width_threshold - current_width\n","            cropped_image = crop_image_width(line_np, remaining_width)\n","            stitched_row.append(cropped_image)\n","\n","            # Pad all images in the row to match the height of the tallest image\n","            max_row_height = max(img.shape[0] for img in stitched_row)\n","            padded_row = [pad_image_to_height(img, max_row_height) for img in stitched_row]\n","            stitched_row_img = np.hstack(padded_row)\n","            stitched_row_img = crop_image_top_bottom(stitched_row_img)\n","            stitched_rows.append(stitched_row_img)\n","\n","            # Update the total width of the stitched image (for padding rows)\n","            max_row_width = max(max_row_width, stitched_row_img.shape[1])\n","            current_height += max_row_height\n","\n","            # Check if the current height exceeds the height threshold\n","            if current_height > height_threshold:\n","                # Pad all rows to the same width, aligning to the left if specified\n","                padded_rows = [pad_image_to_width(row, max_row_width, align_left=align_left) for row in stitched_rows]\n","                stitched_image = np.vstack(padded_rows)\n","\n","                # Add margins around the entire stitched image\n","                stitched_image_with_margin = add_margin(stitched_image, 100)\n","\n","                # Display and save the image with margins\n","                display_image_at_actual_size(stitched_image_with_margin, save_path=pdf_pages)\n","\n","                # Reset for the next set of rows\n","                stitched_rows = []\n","                current_height = 0\n","\n","            # Reset for the next row with the remaining portion of the image\n","            stitched_row = [line_np[:, remaining_width:]]  # Remaining part of the current image\n","            current_width = w - remaining_width\n","            max_row_height = h\n","        else:\n","            # Add the image to the current row\n","            stitched_row.append(line_np)\n","            current_width += w\n","            max_row_height = max(max_row_height, h)  # Update the tallest image in the row\n","\n","    # Handle any remaining images in the last row\n","    if stitched_row:\n","        max_row_height = max(img.shape[0] for img in stitched_row)  # Ensure height consistency\n","        padded_row = [pad_image_to_height(img, max_row_height) for img in stitched_row]\n","        stitched_row_img = np.hstack(padded_row)\n","        stitched_rows.append(stitched_row_img)\n","\n","    # Display and save any remaining stitched rows if they don't reach the height threshold\n","    if stitched_rows:\n","        # Pad all rows to the same width before stacking, aligning to the left if specified\n","        max_row_width = max(row.shape[1] for row in stitched_rows)  # Get max width again\n","        padded_rows = [pad_image_to_width(row, max_row_width, align_left=align_left) for row in stitched_rows]\n","        stitched_image = np.vstack(padded_rows)\n","\n","        # Add margins around the entire stitched image\n","        stitched_image_with_margin = add_margin(stitched_image, margin)\n","\n","        # Display and save the image with margins\n","        display_image_at_actual_size(stitched_image_with_margin, save_path=pdf_pages)\n","\n","    pdf_pages.close()\n"],"metadata":{"id":"w7DuqogeNGdw"},"execution_count":null,"outputs":[]}]}