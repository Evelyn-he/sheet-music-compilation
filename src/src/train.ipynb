{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["uFZNJgyvo-jf"],"mount_file_id":"1pfib8eoz1uahVpQt9quSCdmz2I9djgzs","authorship_tag":"ABX9TyNuByrmNKR72wBt5hzmHxv5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qahm_dNvOvv","executionInfo":{"status":"ok","timestamp":1727584683950,"user_tz":240,"elapsed":9063,"user":{"displayName":"Evelyn He","userId":"10114916118247437564"}},"outputId":"2dad384c-a413-4738-d70f-507ab9270402"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# 1.0  YOLO To Detect Sections Of Music"],"metadata":{"id":"uFZNJgyvo-jf"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mq35buu3KWD_","executionInfo":{"status":"ok","timestamp":1727401209932,"user_tz":240,"elapsed":12891,"user":{"displayName":"Evelyn He","userId":"10114916118247437564"}},"outputId":"11476a12-90bc-4f46-e2d2-f512940c0f8b","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: ultralytics==8.0.117 in /usr/local/lib/python3.10/dist-packages (8.0.117)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (3.7.1)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (10.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (1.13.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (2.4.1+cu121)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (0.19.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (4.66.5)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (2.1.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (0.13.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.117) (5.9.5)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.117) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.117) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.117) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.117) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.117) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.117) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.117) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.117) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.117) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.117) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.117) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.117) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.117) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.117) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.117) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.117) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.117) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.117) (2024.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics==8.0.117) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics==8.0.117) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics==8.0.117) (1.3.0)\n","Requirement already satisfied: albumentations==1.4.0 in /usr/local/lib/python3.10/dist-packages (1.4.0)\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (1.26.4)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (1.13.1)\n","Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (0.24.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (6.0.2)\n","Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (0.0.4)\n","Requirement already satisfied: opencv-python>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.0) (4.10.0.84)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.4.0) (1.5.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.4.0) (4.12.2)\n","Requirement already satisfied: opencv-python-headless>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.4.0) (4.10.0.84)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (3.3)\n","Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (10.4.0)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (2.35.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (2024.9.20)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (24.1)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.0) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.4.0) (3.5.0)\n"]}],"source":["!pip install opencv-python ultralytics==8.0.117\n","!pip install albumentations==1.4.0"]},{"cell_type":"code","source":["import cv2\n","from ultralytics import YOLO\n","from google.colab.patches import cv2_imshow\n","import torch\n","from datetime import datetime\n","\n","now = datetime.now()\n","file_name_format = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n","\n","# Check if CUDA is available\n","print(torch.cuda.is_available())\n","\n","model = YOLO('yolov8n.pt')\n","\n","model.train(\n","    data=\"/content/drive/MyDrive/Sheet Music ML/sheet-music/dataset/data.yaml\",\n","    epochs=30,\n","    imgsz=640,\n","    batch=2,\n","    project='/content/drive/MyDrive/Sheet Music ML/sheet-music/models/',\n","    name=file_name_format,\n","    device='cuda')\n","\n","# Fine tune model on custom dataset\n","# model.train(\n","#     data=\"/content/drive/MyDrive/Sheet Music ML/sheet-music/dataset/data.yaml\",\n","#     epochs=30,\n","#     imgsz=640,\n","#     batch=4,\n","#     project='/content/drive/MyDrive/Sheet Music ML/sheet-music/models/',\n","#     name=file_name_format)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HhoyVCsQMbP9","executionInfo":{"status":"ok","timestamp":1727402231787,"user_tz":240,"elapsed":72146,"user":{"displayName":"Evelyn He","userId":"10114916118247437564"}},"outputId":"853fd642-95dd-43a7-f953-1a09cfc246e5","collapsed":true},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["True\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:511: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(file, map_location='cpu'), file  # load\n","New https://pypi.org/project/ultralytics/8.2.102 available 😃 Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.0.117 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/MyDrive/Sheet Music ML/sheet-music/dataset/data.yaml, epochs=30, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=/content/drive/MyDrive/Sheet Music ML/sheet-music/models/, name=2024-09-27_01-40-26, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/Sheet Music ML/sheet-music/models/2024-09-27_01-40-26\n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n","Model summary: 225 layers, 3011238 parameters, 3011222 gradients\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Sheet Music ML/sheet-music/models/2024-09-27_01-40-26', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:511: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(file, map_location='cpu'), file  # load\n","WARNING ⚠️ NMS time limit 0.550s exceeded\n","/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/utils/checks.py:372: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(True):\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = amp.GradScaler(enabled=self.amp)\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Sheet Music ML/sheet-music/dataset/train/labels.cache... 331 images, 9 backgrounds, 0 corrupt: 100%|██████████| 340/340 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Sheet Music ML/sheet-music/dataset/val/labels.cache... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<?, ?it/s]\n","Plotting labels to /content/drive/MyDrive/Sheet Music ML/sheet-music/models/2024-09-27_01-40-26/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/Sheet Music ML/sheet-music/models/2024-09-27_01-40-26\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","  0%|          | 0/170 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py:328: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(self.amp):\n","       1/30     0.361G     0.9463      1.983      1.235         36        640: 100%|██████████| 170/170 [00:32<00:00,  5.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\n","                   all         10         82      0.692      0.757      0.771      0.586\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/30     0.377G     0.6884      1.155      1.072         16        640: 100%|██████████| 170/170 [00:28<00:00,  5.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.93it/s]\n","                   all         10         82      0.806      0.875      0.862      0.804\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/30     0.375G     0.6742      1.044       1.05         12        640: 100%|██████████| 170/170 [00:31<00:00,  5.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.59it/s]\n","                   all         10         82      0.942      0.951      0.958      0.908\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/30     0.357G     0.6738      0.984      1.034         34        640: 100%|██████████| 170/170 [00:30<00:00,  5.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.35it/s]\n","                   all         10         82      0.973      0.954      0.964       0.93\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/30     0.354G     0.6356     0.9451      1.024         31        640: 100%|██████████| 170/170 [00:33<00:00,  5.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.51it/s]\n","                   all         10         82      0.961      0.931      0.958      0.941\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/30     0.354G     0.5712     0.8395      1.002         17        640: 100%|██████████| 170/170 [00:35<00:00,  4.78it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.15it/s]\n","                   all         10         82      0.982      0.954      0.972      0.947\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/30     0.377G     0.5539     0.8031     0.9922         15        640: 100%|██████████| 170/170 [00:28<00:00,  5.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  9.92it/s]\n","                   all         10         82      0.973      0.964       0.97      0.936\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/30     0.354G     0.5235     0.7371     0.9774         21        640: 100%|██████████| 170/170 [00:31<00:00,  5.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.90it/s]\n","                   all         10         82      0.954       0.96      0.957      0.876\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/30     0.357G     0.5132     0.7007      0.965         52        640: 100%|██████████| 170/170 [00:28<00:00,  5.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.02it/s]\n","                   all         10         82       0.97      0.955      0.957      0.911\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/30     0.354G     0.4914       0.69     0.9631         26        640: 100%|██████████| 170/170 [00:31<00:00,  5.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.54it/s]\n","                   all         10         82      0.971      0.963      0.971      0.947\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/30     0.375G     0.4791     0.6521     0.9625         30        640: 100%|██████████| 170/170 [00:34<00:00,  4.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.44it/s]\n","                   all         10         82      0.948      0.971      0.967      0.949\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/30     0.377G     0.4382     0.5961     0.9278         31        640: 100%|██████████| 170/170 [00:27<00:00,  6.09it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  9.15it/s]\n","                   all         10         82      0.958      0.972      0.965      0.957\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/30     0.354G     0.4113     0.5494     0.9126         12        640: 100%|██████████| 170/170 [00:32<00:00,  5.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  9.38it/s]\n","                   all         10         82      0.972      0.972      0.971      0.966\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/30     0.357G     0.4237     0.5597     0.9248         20        640: 100%|██████████| 170/170 [00:29<00:00,  5.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.22it/s]\n","                   all         10         82      0.947       0.97      0.976      0.964\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/30     0.357G     0.4207     0.6033     0.9354         27        640: 100%|██████████| 170/170 [00:30<00:00,  5.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.06it/s]\n","                   all         10         82      0.973      0.972      0.965      0.953\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/30     0.377G     0.4223     0.5403     0.9321         39        640: 100%|██████████| 170/170 [00:31<00:00,  5.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.50it/s]\n","                   all         10         82      0.961      0.969      0.965      0.956\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/30     0.354G     0.4096     0.5217     0.9247         27        640: 100%|██████████| 170/170 [00:28<00:00,  6.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00, 11.50it/s]\n","                   all         10         82      0.972      0.968      0.973      0.968\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/30     0.375G     0.3951     0.5138     0.9121         26        640: 100%|██████████| 170/170 [00:36<00:00,  4.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00, 10.19it/s]\n","                   all         10         82      0.968       0.97       0.97      0.953\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/30     0.354G     0.3895     0.5028     0.9214         12        640: 100%|██████████| 170/170 [00:30<00:00,  5.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.86it/s]\n","                   all         10         82      0.956      0.972      0.958      0.947\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/30     0.354G     0.3793     0.4703      0.911         25        640: 100%|██████████| 170/170 [00:29<00:00,  5.83it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.74it/s]\n","                   all         10         82      0.961      0.968      0.964      0.945\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/30     0.354G     0.3745     0.4898     0.9071         18        640: 100%|██████████| 170/170 [00:33<00:00,  5.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  8.84it/s]\n","                   all         10         82       0.97      0.972      0.969      0.942\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/30     0.375G     0.3543     0.4487     0.9025         23        640: 100%|██████████| 170/170 [00:28<00:00,  5.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.90it/s]\n","                   all         10         82      0.964      0.966      0.971      0.959\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/30     0.375G     0.3643     0.4521     0.9079         37        640: 100%|██████████| 170/170 [00:31<00:00,  5.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.97it/s]\n","                   all         10         82      0.953      0.972       0.96      0.955\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/30     0.357G     0.3459     0.4548     0.9114         25        640: 100%|██████████| 170/170 [00:30<00:00,  5.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.36it/s]\n","                   all         10         82      0.973       0.97      0.958      0.953\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/30     0.354G     0.3298     0.4356     0.8943         21        640: 100%|██████████| 170/170 [00:32<00:00,  5.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00, 10.04it/s]\n","                   all         10         82      0.966      0.971      0.959      0.951\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/30     0.354G     0.3445     0.4736     0.9025         21        640: 100%|██████████| 170/170 [00:32<00:00,  5.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00, 11.24it/s]\n","                   all         10         82      0.971       0.97       0.97      0.968\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/30     0.354G     0.3124     0.3983     0.8893         18        640: 100%|██████████| 170/170 [00:28<00:00,  5.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  9.74it/s]\n","                   all         10         82      0.972      0.972       0.97      0.969\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/30     0.354G     0.3165     0.4337      0.899         28        640: 100%|██████████| 170/170 [00:31<00:00,  5.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.91it/s]\n","                   all         10         82      0.972      0.957       0.97      0.969\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/30     0.357G     0.3143     0.4191      0.891         42        640: 100%|██████████| 170/170 [00:29<00:00,  5.79it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.94it/s]\n","                   all         10         82      0.962       0.97      0.969      0.965\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/30     0.357G     0.2956      0.384     0.8846         31        640: 100%|██████████| 170/170 [00:29<00:00,  5.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.82it/s]\n","                   all         10         82      0.973      0.972       0.97      0.966\n","\n","30 epochs completed in 0.272 hours.\n","/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/utils/torch_utils.py:390: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  x = torch.load(f, map_location=torch.device('cpu'))\n","Optimizer stripped from /content/drive/MyDrive/Sheet Music ML/sheet-music/models/2024-09-27_01-40-26/weights/last.pt, 6.2MB\n","Optimizer stripped from /content/drive/MyDrive/Sheet Music ML/sheet-music/models/2024-09-27_01-40-26/weights/best.pt, 6.2MB\n","\n","Validating /content/drive/MyDrive/Sheet Music ML/sheet-music/models/2024-09-27_01-40-26/weights/best.pt...\n","Ultralytics YOLOv8.0.117 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:511: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(file, map_location='cpu'), file  # load\n","Model summary (fused): 168 layers, 3006038 parameters, 0 gradients\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.12it/s]\n","                   all         10         82      0.972      0.957       0.97      0.968\n","           sheet-music         10         10      0.987          1      0.995      0.995\n","                   bar         10         72      0.956      0.913      0.945      0.942\n","Speed: 1.2ms preprocess, 27.5ms inference, 0.0ms loss, 6.2ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/Sheet Music ML/sheet-music/models/2024-09-27_01-40-26\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:511: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(file, map_location='cpu'), file  # load\n"]}]},{"cell_type":"markdown","source":["# 2.0 Siamese Neural Network To Detect Line Changes"],"metadata":{"id":"3NsoqNfCpykW"}},{"cell_type":"code","source":["# load data\n","\n","import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from torchvision import transforms\n","import torch\n","\n","transform = transforms.Compose([transforms.Resize((224, 224)),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                                     std=[0.229, 0.224, 0.225])  # Same as ImageNet\n","                                ])\n","\n","path = \"/content/drive/MyDrive/Sheet Music ML/sheet-music/siamese_dataset/\"\n","folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n","\n","dataset = []\n","images_untouched = []\n","labels = []\n","\n","for folder in folders:\n","  images = [file for file in os.listdir(path + folder) if file.endswith(\".png\")]\n","  with open(path + folder + \"/label.txt\", 'r') as label_file:\n","    for line in label_file:\n","      label = int(line.strip())\n","\n","  img_tensors = [transform(Image.open(os.path.join(path, folder, image))) for image in images]\n","\n","  if len(img_tensors) == 2:\n","    dataset.append(img_tensors)\n","    images_untouched.append([Image.open(os.path.join(path, folder, image)) for image in images])\n","    labels.append(label)\n","  else:\n","    print(f\"Corrupted folder {folder} does not contain 2 images, skipping\")\n","\n","from collections import Counter\n","label_counts = Counter(labels)\n","num_zeros = label_counts[0]\n","num_ones = label_counts[1]\n","print(f\"Number of 0s: {num_zeros}\")\n","print(f\"Number of 1s: {num_ones}\")\n","\n","labels = torch.tensor(labels)\n","\n","\n","# for i in range(len(dataset)):\n","#   plt.imshow(dataset[i][0])\n","#   plt.show()\n","#   plt.imshow(dataset[i][1])\n","#   plt.show()\n","#   print(labels[i])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"SJ4xS_EUeKsz","executionInfo":{"status":"ok","timestamp":1727585558004,"user_tz":240,"elapsed":695185,"user":{"displayName":"Evelyn He","userId":"10114916118247437564"}},"outputId":"3b7cc5a7-0ff1-4daf-ee1a-9c5b2e0a6ce6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of 0s: 512\n","Number of 1s: 494\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torch.nn.functional as F\n","\n","class SiameseNetwork(nn.Module):\n","  def __init__(self):\n","    super(SiameseNetwork, self).__init__()\n","    self.resnet = models.resnet18(pretrained=True)\n","    self.resnet.fc = nn.Identity() # Remove classification head\n","\n","    self.fc1 = nn.Linear(512, 256)\n","    self.fc2 = nn.Linear(256, 64)\n","\n","  def forward_one(self, x):\n","    x = self.resnet(x)\n","    x = F.relu(self.fc1(x))\n","    x = self.fc2(x)\n","    return x\n","\n","  def forward(self, input1, input2):\n","    output1 = self.forward_one(input1)\n","    output2 = self.forward_one(input2)\n","    return output1, output2\n","\n","class ContrastiveLoss(nn.Module):\n","  def __init__(self, margin=1.0):\n","    super(ContrastiveLoss, self).__init__()\n","    self.margin = margin\n","\n","  def forward(self, output1, output2, label):\n","    euclidean_distance = F.pairwise_distance(output1, output2)\n","    loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n","                                  (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n","    return loss_contrastive\n"],"metadata":{"id":"mdky4mEJizSj","executionInfo":{"status":"ok","timestamp":1727586824158,"user_tz":240,"elapsed":229,"user":{"displayName":"Evelyn He","userId":"10114916118247437564"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","from datetime import datetime\n","\n","model = SiameseNetwork()\n","criterion = ContrastiveLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","num_epochs = 30\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","for epoch in range(num_epochs):\n","  for i in range(len(dataset)):\n","    img1 = dataset[i][0].to(device)\n","    img2 = dataset[i][1].to(device)\n","    label = labels[i].float().to(device)\n","    optimizer.zero_grad()\n","\n","    output1, output2 = model(img1.unsqueeze(0), img2.unsqueeze(0))\n","    loss = criterion(output1, output2, label)\n","    loss.backward()\n","    optimizer.step()\n","\n","  print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n","  print(f\"Loss: {loss.item()}\")\n","\n","now = datetime.now()\n","file_name_format = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n","path = '/content/drive/MyDrive/Sheet Music ML/sheet-music/models/siamese/'+file_name_format+'.pt'\n","print(f\"Saving model to file {path}\")\n","\n","torch.save(model.state_dict(), path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z7s7YaMpmLNa","executionInfo":{"status":"ok","timestamp":1727587461267,"user_tz":240,"elapsed":635135,"user":{"displayName":"Evelyn He","userId":"10114916118247437564"}},"outputId":"f24c25b5-600a-4e75-ea3c-07a6d715f1c1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30 completed.\n","Loss: 0.00024576165014877915\n","Epoch 2/30 completed.\n","Loss: 0.004225281532853842\n","Epoch 3/30 completed.\n","Loss: 0.007457312196493149\n","Epoch 4/30 completed.\n","Loss: 0.020294873043894768\n","Epoch 5/30 completed.\n","Loss: 0.1177394837141037\n","Epoch 6/30 completed.\n","Loss: 0.11159007996320724\n","Epoch 7/30 completed.\n","Loss: 0.007048579398542643\n","Epoch 8/30 completed.\n","Loss: 0.011517849750816822\n","Epoch 9/30 completed.\n","Loss: 0.07634278386831284\n","Epoch 10/30 completed.\n","Loss: 0.04363927245140076\n","Epoch 11/30 completed.\n","Loss: 0.0010042472276836634\n","Epoch 12/30 completed.\n","Loss: 0.01789710856974125\n","Epoch 13/30 completed.\n","Loss: 0.006334254983812571\n","Epoch 14/30 completed.\n","Loss: 0.034578897058963776\n","Epoch 15/30 completed.\n","Loss: 0.013516903854906559\n","Epoch 16/30 completed.\n","Loss: 0.00436874246224761\n","Epoch 17/30 completed.\n","Loss: 0.004754906520247459\n","Epoch 18/30 completed.\n","Loss: 0.0009877593256533146\n","Epoch 19/30 completed.\n","Loss: 0.007632074411958456\n","Epoch 20/30 completed.\n","Loss: 0.0010828913655132055\n","Epoch 21/30 completed.\n","Loss: 0.0034373209346085787\n","Epoch 22/30 completed.\n","Loss: 0.011955935508012772\n","Epoch 23/30 completed.\n","Loss: 0.05652449280023575\n","Epoch 24/30 completed.\n","Loss: 0.0018772744806483388\n","Epoch 25/30 completed.\n","Loss: 0.002030028495937586\n","Epoch 26/30 completed.\n","Loss: 0.004328960087150335\n","Epoch 27/30 completed.\n","Loss: 0.012810003012418747\n","Epoch 28/30 completed.\n","Loss: 0.002934287302196026\n","Epoch 29/30 completed.\n","Loss: 0.0012090058298781514\n","Epoch 30/30 completed.\n","Loss: 0.013783340342342854\n","Saving model to file /content/drive/MyDrive/Sheet Music ML/sheet-music/models/siamese/2024-09-29_05-24-21.pt\n"]}]}]}